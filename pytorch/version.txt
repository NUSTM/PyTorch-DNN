PyTorch库编写的神经网络模型
Ubuntu 16.04 & PyTorch 1.0

Version 0.11
  * 1 逻辑优化和速度优化，降低50%系统内存占用空间并提升超过2倍的运行速度
      修复数据读取异常消耗内存的问题
      优化数据读取方式及与GPU的交互方式，使用略高的显存消耗再次加速运行
      删除base.cuda_enable参数，添加函数exec._model_to_cuda()，优化模型导入GPU的方式
  * 2 支持模型参数初始化
      添加函数CM.init_weight()，为CNN模型提供权重初始化
      添加函数RM.init_weight()，为RNN模型提供权重初始化
    3 添加参数base.data_shuffle()，支持打乱数据操作
  * 4 支持Transformer
    5 调整RNN.embedding_layer()至layer.embedding_layer()

Version 0.10
  * 1 代码结构调整，拆分为base/layer/model/exec四个模块
      添加contrib模块存放扩展模型
      在{exec}下添加执行模块基类<exec>
  * 2 支持CNN
      创建CNN层<CNN_layer(CL)/nn.Module>，并提供权重初始化
      创建CNN模型<CNN_model(CM)/nn.Module&base>
      创建CNN分类模型<CNN_classify(CC)/exec>
  * 3 添加单机多GPU并行支持
      添加参数base.n_gpu
      更新exec，支持多GPU并行
    4 调整内部运行函数对复杂模型的适用性
      更新exec._run_train()&exec._run_test()
    5 调整LSTM层封装功能，去除内部封装Attention选择
      更新LL&RM类，重新使用Attention
    6 调整{layer}中的所有层级，支持无长度输入以增强适用性

Version 0.9
    1 修复输出显示
      修复自适应显示导致溢出的问题
      修复k折交叉验证时，输出类别数量错误的问题
      修复功能性函数的输出异常
      添加RC._init_display()函数，取消col/width参数，强制自适应
    2 修复序列标注模型中必须使用投票机制的问题
    3 修复无法取某一类别的P/R/F作为模型评判标准的问题
      更新全部predict_analysis相关机制和输出
    4 调整类命名，更符合类的实际定位(层-模型-分类/序列执行)
      更名基类<RNN>为<base>
      更名自注意力机制层<self_attention_model>为<self_attention_layer(SAL)>
      更名LSTM层<LSTM_model>为<LSTM_layer(LL)>
  * 5 创建Softmax层/全连接层<softmax_layer(SL)/nn.Module>
      更新RCM类，调用SL
  * 6 支持层级参数初始化
      添加函数LL.init_weight()，为LSTM层提供权重初始化
      添加函数SAL.init_weight()，为自注意力层提供权重初始化
      添加函数SL.init_weight()，为Softmax层提供权重初始化

Version 0.8
    1 合并分类模型和序列标注模型
      创建合并模型<RNN_model(RM)/nn.Module&RNN>
      删除分类模型<RNN_classify_model(RCM)>和序列标注模型<RNN_sequence_model(RSM)>
    2 调整分类模型中函数的适用性，避免在序列标注模型中重写
      更新函数RC.run_train()&RC.run_test()
      删除函数RS.run_train()&RS.run_test()
    3 进行运行函数的私有化
      更名函数RC.run_train()为RC._run_train()，其它函数同样
    4 调整功能函数对运行函数的输入方式
      更新函数RNN.average_several_run()和RNN.grid_search()，适应运行函数可能的多种输入

Version 0.7
    1 修复层次分类中使用Attention的nan值问题
  * 2 创建序列标注模型<RNN_sequence_model(RSM)/RNN_classify_model>
      重写RSM.forward()，构造前向网络结构
  * 3 创建序列标注执行模型<RNN_sequence(RS)/RNN_classify>
      添加函数RNN.vote_sequence()，为重复数据投票
      重写函数RS.run_train()，运行训练数据部分
      重写函数RS.run_test()，运行测试数据部分
      重写函数RS.run()，完成训练-测试运行部分
  * 4 PyTorch版本支持更新到1.0.0

Version 0.6
  * 1 分类模型支持层次分类
      删除参数RNN.max_seq_len和RNN.max_sen_len
      添加参数RNN.n_hierarchy，控制层次数量
      更新RCM类，自适应层次分类和序列长度数据输入
      调整data_dict输入格式，合并所有长度相关数据
  * 2 合并LSTM模型和GRU模型
      创建可添加Attention的RNN模型<LSTM_model/nn.Module>
      整合排序和层次适应
      删除GRU模型<GRU_model>
      更新RCM类，调用<RNN_model>
    3 更名注意力机制模型为<self_attention_model/nn.Module>
    4 添加参数RNN.cuda_enable，适应CPU运行

Version 0.5
  * 1 优化模型运行方式，提取具体运行部分
      添加函数RC.run()，完成训练-测试运行部分
      更新函数RC.train_test()，运行训练-测试数据
      更新函数RC.cross_validation()，运行单一训练集的交叉验证
    2 调整模型可视化输出及控制参数位置
      添加RC.class_name&RC.col&RC.width参数
      更新RC类，去除模型运行部分所需要的输出控制参数
      更新RC类运行函数，添加可视输出等级verbose
    3 添加函数RNN.average_several_run()，支持多次模型运行取平均
    4 支持网格搜索调参
      添加函数RNN.attributes_from_dict()，调整参数
      添加函数RNN.grid_search()，参数网格搜索

Version 0.4
  * 1 创建LSTM模型<LSTM_model/nn.Module>和GRU模型<GRU_model/nn.Module>
      封装LSTM和GRU的执行过程和输出
      更新RCM类，调用LSTM模型和GRU模型
    2 支持L2正则
      添加参数l2_reg
      更新RC类，在优化函数部分添加L2正则
    3 更新默认参数函数default_args()的使用
      调用时取默认参数函数并修改，RNN类不再提供参数默认值

Version 0.3
  * 1 支持Attention操作
      创建注意力机制模型<self_attention/nn.Module>
      添加RNN.use_attention参数
      更新RCM类，支持Attention
    2 调整RC内运行函数的适用性

Version 0.2
    1 添加Embedding支持
      添加RNN.embedding_layer()，设置embedding矩阵
      更新RCM.forward()，使用emb_type参数判断模式
    2 更新RCM类，添加Dropout层

Version 0.1
  * 1 创建基类<RNN>
      添加函数RNN.create_data_loader()，用以导入数据
      添加函数RNN.mod_fold()，k折交叉
  * 2 创建分类模型<RNN_classify_model(RCM)/nn.Module&RNN>
      重写RCM.forward()，构造前向网络结构
  * 3 创建分类执行模型<RNN_classify(RC)/RNN>
      添加函数RC.run_train()，运行训练数据部分
      添加函数RC.run_test()，运行测试数据部分
      添加函数RC.train_test()，运行训练-测试数据
      添加函数RC.train_itself()，运行单一训练集
      添加函数RC.cross_validation()，运行单一训练集的交叉验证
    4 创建默认参数函数default_args()，为模型指定默认参数
    5 模型运行函数均采用最优值代替结束值作为输出
